{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25bb7191",
   "metadata": {},
   "source": [
    "# **SHETH L.U.J. & SIR M.V. COLLEGE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3949ff",
   "metadata": {},
   "source": [
    "**Shreeraj Desai | T075**\n",
    "### Practical No. 3B\n",
    "**Aim**: Feature Scaling and Dummification\n",
    "\n",
    "*   Apply feature-scaling techniques like standardization and normalization to numerical features.\n",
    "*   Perform feature dummification to convert categorical variables into numerical representations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6a67d",
   "metadata": {},
   "source": [
    "## 1. Initial Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7886fb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   month  credit_amount  credit_term  age     sex  \\\n",
      "0      1           7000           12   39    male   \n",
      "1      1          19000            6   20    male   \n",
      "2      1          29000           12   23  female   \n",
      "3      1          10000           12   30    male   \n",
      "4      1          14500           12   25  female   \n",
      "\n",
      "                     education          product_type  having_children_flg  \\\n",
      "0  Secondary special education           Cell phones                    0   \n",
      "1  Secondary special education  Household appliances                    1   \n",
      "2  Secondary special education  Household appliances                    0   \n",
      "3  Secondary special education           Cell phones                    1   \n",
      "4             Higher education           Cell phones                    0   \n",
      "\n",
      "   region  income family_status  phone_operator  is_client  bad_client_target  \n",
      "0       2   21000       Another               0          0                  0  \n",
      "1       2   17000       Another               3          1                  0  \n",
      "2       2   31000       Another               2          0                  0  \n",
      "3       2   31000     Unmarried               3          1                  0  \n",
      "4       2   26000       Married               0          1                  0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df = pd.read_csv('Datasets/clients.csv')\n",
    "\n",
    "# Add a synthetic column for the MultiLabelBinarizer example\n",
    "# df['hobbies'] = [\n",
    "#     (\"sports\", \"reading\"), (\"music\",), (\"sports\", \"cooking\"), (\"reading\", \"music\"), (\"travel\",),\n",
    "#     (\"cooking\",), (\"sports\",), (\"reading\", \"travel\"), (\"music\", \"cooking\"), (\"sports\",), (\"travel\", \"reading\")\n",
    "# ]\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92d6853",
   "metadata": {},
   "source": [
    "## 2. Encoding Nominal Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c27392",
   "metadata": {},
   "source": [
    "### Solution 1: Using scikit-learn's `LabelBinarizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d946f0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded 'product_type' with LabelBinarizer:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "Feature classes: ['Audio & Video' 'Auto' 'Boats' 'Cell phones' \"Childen's goods\" 'Clothing'\n",
      " 'Computers' 'Construction Materials' 'Cosmetics and beauty services'\n",
      " 'Fishing and hunting supplies' 'Fitness' 'Furniture' 'Garden equipment'\n",
      " 'Household appliances' 'Jewelry' 'Medical services' 'Music'\n",
      " 'Repair Services' 'Sporting goods' 'Tourism' 'Training' 'Windows & Doors']\n",
      "\n",
      "Reversed transformation (first 5): ['Cell phones' 'Household appliances' 'Household appliances' 'Cell phones'\n",
      " 'Cell phones']\n"
     ]
    }
   ],
   "source": [
    "feature_lb = df[['product_type']]\n",
    "one_hot_encoder = LabelBinarizer()\n",
    "transformed_feature = one_hot_encoder.fit_transform(feature_lb)\n",
    "\n",
    "print(\"One-hot encoded 'product_type' with LabelBinarizer:\")\n",
    "print(transformed_feature)\n",
    "print(\"\\nFeature classes:\", one_hot_encoder.classes_)\n",
    "print(\"\\nReversed transformation (first 5):\", one_hot_encoder.inverse_transform(transformed_feature)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147f17ad",
   "metadata": {},
   "source": [
    "### Solution 2: Using pandas `get_dummies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d75bc012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after applying get_dummies to 'product_type':\n",
      "   month  credit_amount  credit_term  age     sex  \\\n",
      "0      1           7000           12   39    male   \n",
      "1      1          19000            6   20    male   \n",
      "2      1          29000           12   23  female   \n",
      "3      1          10000           12   30    male   \n",
      "4      1          14500           12   25  female   \n",
      "\n",
      "                     education  having_children_flg  region  income  \\\n",
      "0  Secondary special education                    0       2   21000   \n",
      "1  Secondary special education                    1       2   17000   \n",
      "2  Secondary special education                    0       2   31000   \n",
      "3  Secondary special education                    1       2   31000   \n",
      "4             Higher education                    0       2   26000   \n",
      "\n",
      "  family_status  ...  prod_Garden equipment  prod_Household appliances  \\\n",
      "0       Another  ...                  False                      False   \n",
      "1       Another  ...                  False                       True   \n",
      "2       Another  ...                  False                       True   \n",
      "3     Unmarried  ...                  False                      False   \n",
      "4       Married  ...                  False                      False   \n",
      "\n",
      "   prod_Jewelry  prod_Medical services  prod_Music  prod_Repair Services  \\\n",
      "0         False                  False       False                 False   \n",
      "1         False                  False       False                 False   \n",
      "2         False                  False       False                 False   \n",
      "3         False                  False       False                 False   \n",
      "4         False                  False       False                 False   \n",
      "\n",
      "   prod_Sporting goods  prod_Tourism  prod_Training  prod_Windows & Doors  \n",
      "0                False         False          False                 False  \n",
      "1                False         False          False                 False  \n",
      "2                False         False          False                 False  \n",
      "3                False         False          False                 False  \n",
      "4                False         False          False                 False  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "df_dummies = pd.get_dummies(df, columns=['product_type'], prefix='prod')\n",
    "print(\"DataFrame after applying get_dummies to 'product_type':\")\n",
    "print(df_dummies.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16b728b",
   "metadata": {},
   "source": [
    "### Solution 3: Handling Multi-Class Features with `MultiLabelBinarizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b25ac05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded 'product_type' column:\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "Classes found: [' ' '&' \"'\" 'A' 'B' 'C' 'D' 'F' 'G' 'H' 'J' 'M' 'R' 'S' 'T' 'V' 'W' 'a'\n",
      " 'b' 'c' 'd' 'e' 'g' 'h' 'i' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v'\n",
      " 'w' 'y']\n"
     ]
    }
   ],
   "source": [
    "multiclass_feature = df['product_type']\n",
    "one_hot_multiclass = MultiLabelBinarizer()\n",
    "transformed_multiclass = one_hot_multiclass.fit_transform(multiclass_feature)\n",
    "\n",
    "print(\"One-hot encoded 'product_type' column:\")\n",
    "print(transformed_multiclass)\n",
    "print(\"\\nClasses found:\", one_hot_multiclass.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98aeb2a",
   "metadata": {},
   "source": [
    "## 3. Encoding Ordinal Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7e233b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vs. Encoded 'education' column:\n",
      "                     education education_encoded\n",
      "0  Secondary special education                 2\n",
      "1  Secondary special education                 2\n",
      "2  Secondary special education                 2\n",
      "3  Secondary special education                 2\n",
      "4             Higher education                 3\n",
      "5  Secondary special education                 2\n",
      "6             Higher education                 3\n",
      "7             Higher education                 3\n",
      "8  Secondary special education                 2\n",
      "9  Secondary special education                 2\n"
     ]
    }
   ],
   "source": [
    "df_ordinal = df.copy()\n",
    "education_mapper = {\n",
    "    \"Secondary education\": 1,\n",
    "    \"Secondary special education\": 2,\n",
    "    \"Higher education\": 3,\n",
    "    \"PhD\": 4\n",
    "}\n",
    "df_ordinal['education_encoded'] = df_ordinal['education'].replace(education_mapper)\n",
    "\n",
    "print(\"Original vs. Encoded 'education' column:\")\n",
    "print(df_ordinal[['education', 'education_encoded']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5bd55b",
   "metadata": {},
   "source": [
    "## 4. Encoding Dictionaries of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c6c3945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting feature matrix from dictionaries (first 5 rows):\n",
      "[[1. 0. 0. 2. 0. 1.]\n",
      " [1. 0. 0. 2. 0. 1.]\n",
      " [1. 0. 0. 2. 1. 0.]\n",
      " [0. 0. 1. 2. 0. 1.]\n",
      " [0. 1. 0. 2. 1. 0.]]\n",
      "\n",
      "Feature names created by DictVectorizer: ['family_status=Another' 'family_status=Married' 'family_status=Unmarried'\n",
      " 'region' 'sex=female' 'sex=male']\n"
     ]
    }
   ],
   "source": [
    "data_dict = df[['sex', 'family_status', 'region']].to_dict(orient='records')\n",
    "dictvectorizer = DictVectorizer(sparse=False)\n",
    "features_dict = dictvectorizer.fit_transform(data_dict)\n",
    "\n",
    "print(\"Resulting feature matrix from dictionaries (first 5 rows):\")\n",
    "print(features_dict[:5])\n",
    "print(\"\\nFeature names created by DictVectorizer:\", dictvectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6a045",
   "metadata": {},
   "source": [
    "## 5. Imputing Missing Class Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d2e518",
   "metadata": {},
   "source": [
    "### Solution 1: Using a KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "613203a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Imputing Missing Values with KNN ###\n",
      "Missing values in 'having_children_flg' before KNN imputation: 0\n",
      "Missing values in 'having_children_flg' after KNN imputation: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Corrected Code for KNN Imputation\n",
    "\n",
    "print(\"### Imputing Missing Values with KNN ###\")\n",
    "df_impute_knn = pd.read_csv('Datasets/clients2.csv')\n",
    "\n",
    "features_for_imputation = ['age', 'income']\n",
    "\n",
    "# Split data into training (no missing values) and prediction (missing values) sets\n",
    "train_data = df_impute_knn[df_impute_knn['having_children_flg'].notna()]\n",
    "predict_data = df_impute_knn[df_impute_knn['having_children_flg'].isna()]\n",
    "\n",
    "# --- ADD THIS CHECK ---\n",
    "# Only proceed if there are missing values to predict\n",
    "if not predict_data.empty:\n",
    "    # Also ensure there is enough data to train the model\n",
    "    if len(train_data) >= 3: # k=3 for our classifier\n",
    "        clf_knn = KNeighborsClassifier(3, weights='distance')\n",
    "        trained_model = clf_knn.fit(train_data[features_for_imputation], train_data['having_children_flg'])\n",
    "\n",
    "        # Predict and fill the missing values\n",
    "        imputed_values = trained_model.predict(predict_data[features_for_imputation])\n",
    "        df_impute_knn.loc[df_impute_knn['having_children_flg'].isna(), 'having_children_flg'] = imputed_values\n",
    "    else:\n",
    "        print(\"Warning: Not enough data to train the KNN imputer. Skipping imputation.\")\n",
    "else:\n",
    "    print(\"No missing values found in 'having_children_flg' to impute.\")\n",
    "\n",
    "\n",
    "print(\"Missing values in 'having_children_flg' before KNN imputation:\", df['having_children_flg'].isna().sum())\n",
    "print(\"Missing values in 'having_children_flg' after KNN imputation:\", df_impute_knn['having_children_flg'].isna().sum())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475ec42",
   "metadata": {},
   "source": [
    "### Solution 2: Using the Most Frequent Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7063f636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'having_children_flg' before SimpleImputer: 0\n",
      "Missing values in 'having_children_flg' after SimpleImputer: 0\n"
     ]
    }
   ],
   "source": [
    "df_impute_freq = df.copy()\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df_impute_freq['having_children_flg'] = imputer.fit_transform(df_impute_freq[['having_children_flg']])\n",
    "\n",
    "print(\"Missing values in 'having_children_flg' before SimpleImputer:\", df['having_children_flg'].isna().sum())\n",
    "print(\"Missing values in 'having_children_flg' after SimpleImputer:\", df_impute_freq['having_children_flg'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e7fee7",
   "metadata": {},
   "source": [
    "## 6. Handling Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85b44483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution for 'bad_client_target':\n",
      "bad_client_target\n",
      "0    1527\n",
      "1     196\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = df['bad_client_target'].value_counts()\n",
    "print(\"Class distribution for 'bad_client_target':\")\n",
    "print(class_counts)\n",
    "\n",
    "df_model = df.dropna().copy()\n",
    "X = df_model[['credit_amount', 'credit_term', 'age', 'income']]\n",
    "y = df_model['bad_client_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f477608",
   "metadata": {},
   "source": [
    "### Solution 1: Using Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82639328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier with balanced class weights:\n",
      "RandomForestClassifier(class_weight='balanced', random_state=42)\n"
     ]
    }
   ],
   "source": [
    "balanced_rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "print(\"RandomForestClassifier with balanced class weights:\")\n",
    "print(balanced_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5b2e0",
   "metadata": {},
   "source": [
    "### Solution 2: Downsampling the Majority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33ff80bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after downsampling:\n",
      "bad_client_target\n",
      "0    196\n",
      "1    196\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_majority = df_model[df_model.bad_client_target == 0]\n",
    "df_minority = df_model[df_model.bad_client_target == 1]\n",
    "df_majority_downsampled = resample(df_majority,\n",
    "                                 replace=False,\n",
    "                                 n_samples=len(df_minority),\n",
    "                                 random_state=42)\n",
    "\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "print(\"Class distribution after downsampling:\")\n",
    "print(df_downsampled.bad_client_target.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8471eedb",
   "metadata": {},
   "source": [
    "### Solution 3: Upsampling the Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dbabf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after upsampling:\n",
      "bad_client_target\n",
      "0    1527\n",
      "1    1527\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_minority_upsampled = resample(df_minority,\n",
    "                                 replace=True,\n",
    "                                 n_samples=len(df_majority),\n",
    "                                 random_state=42)\n",
    "\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "print(\"Class distribution after upsampling:\")\n",
    "print(df_upsampled.bad_client_target.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
